{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch0/ilya/locDoc/miniconda2/envs/venvtf/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "from collections import namedtuple\n",
    "import itertools\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import windows as win\n",
    "from rle import myrlestring\n",
    "import salt_baseline as sb\n",
    "import salt_data as sd\n",
    "import fst3d_feat as fst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import operator\n",
    "import h5py\n",
    "import hdf5storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_PATH = '/scratch0/ilya/locDoc/data/hyperspec'\n",
    "DATASET_PATH = '/scratch0/ilya/locDoc/data/hyperspec/datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_contents = sio.loadmat(os.path.join(DATASET_PATH, 'Pavia_center_right'))\n",
    "data = mat_contents['Pavia_center_right'].astype(np.float32)\n",
    "data /= np.max(np.abs(data))\n",
    "mat_contents = sio.loadmat(os.path.join(DATASET_PATH, 'Pavia_center_right_gt.mat'))\n",
    "labels = mat_contents['Pavia_center_right_gt']\n",
    "traintestfilename = 'Pavia_center_right_gt_traintest_coarse_128px128p.mat'\n",
    "netO = fst.Pavia_net()\n",
    "\n",
    "[height, width, nbands] = data.shape\n",
    "\n",
    "\n",
    "all_pixels = np.array(list(itertools.product(range(width),range(height))))\n",
    "flat_labels = labels.transpose().reshape(height*width)\n",
    "# nlabels = len(set(flat_labels.tolist())) - 1\n",
    "\n",
    "ap = np.array(netO.addl_padding)\n",
    "assert np.all(ap % 2 == 0), 'Assymetric is not supported'\n",
    "# net_in_shape = ap + np.array([1,1,nbands])\n",
    "# x = tf.placeholder(tf.float32, shape=net_in_shape)\n",
    "# feat = netO.model_fn(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_data = np.pad(data, ((ap[0]//2,ap[0]//2),(ap[1]//2,ap[1]//2),(ap[2]//2,ap[2]//2)), 'wrap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_contents = None\n",
    "try:\n",
    "    mat_contents = sio.loadmat(os.path.join(DATA_PATH, traintestfilename))\n",
    "except:\n",
    "    mat_contents = hdf5storage.loadmat(os.path.join(DATA_PATH, traintestfilename))\n",
    "train_mask = mat_contents['train_mask'].astype(int).squeeze()\n",
    "test_mask = mat_contents['test_mask'].astype(int).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pixels = np.array(filter(lambda (x,y): labels[y,x]*train_mask[x*height+y] != 0, all_pixels))\n",
    "test_pixels = np.array(filter(lambda (x,y): labels[y,x]*test_mask[x*height+y] != 0, all_pixels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pixels = np.array(filter(lambda (x,y): labels[y,x]*test_mask[x*height+y] != 0, all_pixels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((90909, 2), 90909)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pixels.shape, test_mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 12630/12630 [00:01<00:00, 8499.08it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_item_shape = tuple(map(operator.add, netO.addl_padding, (1,1,data.shape[2])))\n",
    "trainX = np.zeros((train_mask.sum(),) + batch_item_shape)\n",
    "for pixel_i, pixel in enumerate(tqdm(train_pixels, desc='Train')):\n",
    "    # this iterates through columns first\n",
    "    [pixel_x, pixel_y] = pixel\n",
    "    trainX[pixel_i,:,:,:] = padded_data[pixel_y:(pixel_y+ap[0]+1), pixel_x:(pixel_x+ap[1]+1), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90909/90909 [00:09<00:00, 9341.56it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_item_shape = tuple(map(operator.add, netO.addl_padding, (1,1,data.shape[2])))\n",
    "testX = np.zeros((test_mask.sum(),) + batch_item_shape)\n",
    "for pixel_i, pixel in enumerate(tqdm(test_pixels)):\n",
    "    # this iterates through columns first\n",
    "    [pixel_x, pixel_y] = pixel\n",
    "    testX[pixel_i,:,:,:] = padded_data[pixel_y:(pixel_y+ap[0]+1), pixel_x:(pixel_x+ap[1]+1), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fst3d_feat import scat3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "layerO = namedtuple('layerO', ['strides', 'padding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "psi = win.fst3d_psi_factory([7,7,7])\n",
    "phi = win.fst3d_phi_window_3D([7,7,7])\n",
    "layer_params = layerO((3,1,1), 'valid')\n",
    "psis=[psi,psi]\n",
    "layer_params=[layer_params, layer_params, layer_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=(1,120,21,21,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "U1 = scat3d(x, psis[0], layer_params[0])\n",
    "# swap channels with batch\n",
    "U1 = tf.transpose(U1, [4, 1, 2, 3, 0])\n",
    "\n",
    "U2s = []\n",
    "# only procede with increasing frequency paths\n",
    "for res_i, used_params in enumerate(psis[0].filter_params):\n",
    "    increasing_psi = win.fst3d_psi_factory(psis[1].kernel_size, used_params)\n",
    "    if increasing_psi.nfilt > 0:\n",
    "        U2s.append(scat3d(U1[res_i:(res_i+1),:,:,:,:], increasing_psi, layer_params[1]))\n",
    "\n",
    "U2 = tf.concat(U2s, 4)\n",
    "# swap channels with batch\n",
    "U2 = tf.transpose(U2, [4, 1, 2, 3, 0])\n",
    "\n",
    "# convolve with phis\n",
    "S2 = scat3d(U2, phi, layer_params[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(216), Dimension(38), Dimension(15), Dimension(15), Dimension(1)])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def slice_idxs(sig_size, kernel_size):\n",
    "    def slice_idx(s, k, f):\n",
    "        if k % 2 == 0:\n",
    "            raise('not implemented even padding')\n",
    "        else:\n",
    "            return int((s - k - f)//2)\n",
    "    final_size = [1,3,3]\n",
    "    return [slice_idx(s,k,f-1) for s,k,f in zip(sig_size, kernel_size,final_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "[p1b, p1h, p1w] = slice_idxs(U1.shape[1:4], psis[1].kernel_size)\n",
    "[p2b, p2h, p2w] = slice_idxs(x.shape[1:4], psis[0].kernel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "S1 = scat3d(U1[:,(p1b):-(p1b),(p1h):-(p1h), (p1w):-(p1w), :], phi, layer_params[2])\n",
    "S0 = scat3d(x[:, (p2b):-(p2b),(p2h):-(p2h), (p2w):-(p2w), :], phi, layer_params[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(1), Dimension(1), Dimension(3), Dimension(3), Dimension(1)])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(216), Dimension(1), Dimension(3), Dimension(3), Dimension(1)])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(9045), Dimension(2), Dimension(3), Dimension(3), Dimension(1)])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "S2 = tf.reduce_mean(S2,1,keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "SX = tf.squeeze(tf.concat([S0,S1,S2], 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "SX_batch = tf.expand_dims(SX,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 9\n",
    "dropout = 0.25 # Dropout, probability to drop a unit\n",
    "is_training=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1x1 conv replaces PCA step\n",
    "conv1 = tf.layers.conv2d(SX_batch, 1024, 1, data_format='channels_first')\n",
    "# Convolution Layer with filters of size 3\n",
    "conv2 = tf.layers.conv2d(conv1, 512, 3, activation=tf.nn.relu, padding='same', data_format='channels_first')\n",
    "conv2 = tf.layers.max_pooling2d(conv2, 2, 2, data_format='channels_first')\n",
    "# Flatten the data to a 1-D vector for the fully connected layer\n",
    "fc1 = tf.contrib.layers.flatten(conv2)\n",
    "fc1 = tf.layers.dense(fc1, 500)\n",
    "fc1 = tf.layers.dropout(fc1, rate=dropout, training=is_training)\n",
    "fc2 = tf.layers.dense(fc1, 100)\n",
    "out = tf.layers.dense(fc2, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dimension(83358)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.prod(SX_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dimension(52920)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.prod(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
